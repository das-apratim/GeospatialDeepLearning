{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/das-apratim/GeospatialDeepLearning/blob/main/LULC_Classification_Using_MachineLearning_Part1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Image Classification Using K-Means Clustering**  \n",
        "\n",
        "K-Means clustering is an unsupervised machine learning technique used for classifying satellite images into different land cover types based on spectral similarity. It groups pixels with similar spectral characteristics into clusters, making it a useful approach for land use and land cover (LULC) classification without requiring labeled training data.  \n",
        "\n",
        "#### **How It Works**  \n",
        "1. The algorithm randomly initializes cluster centroids based on the number of desired classes.  \n",
        "2. Each pixel is assigned to the nearest centroid based on spectral values.  \n",
        "3. The centroids are recalculated iteratively until cluster assignments stabilize.  \n",
        "4. The final clusters represent different land cover types, such as vegetation, water, and urban areas.  \n",
        "\n",
        "#### **Applications**  \n",
        "- Land cover classification  \n",
        "- Change detection analysis  \n",
        "- Water body identification  \n",
        "- Agricultural monitoring  \n",
        "\n",
        "K-Means is a simple yet effective method for quick and unsupervised image classification, but it requires careful selection of the number of clusters and may benefit from additional preprocessing techniques such as Principal Component Analysis (PCA) or spectral indices to enhance classification accuracy.\n",
        "\n",
        "### Download Sample Data and Unzip"
      ],
      "metadata": {
        "id": "sEPQK878F4xb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GknWHzQhlBS"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/das-apratim/GeospatialDeepLearning/blob/main/data/sampled_data.zip?raw=true -O sampled_data.zip\n",
        "!unzip -q sampled_data.zip -d nz_imagery_sample"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Required Libraries"
      ],
      "metadata": {
        "id": "NDTVbs_CHrS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q rasterio"
      ],
      "metadata": {
        "id": "Uw1tZmMuHu3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "mnNZDCtYHBkR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import rasterio\n",
        "from rasterio.plot import show\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from scipy.ndimage import generic_filter\n",
        "from glob import glob\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "MrPTvqERHEQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read Sentinal Bands"
      ],
      "metadata": {
        "id": "psutNbvB3Tq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentinel-2 band files (Modify this for your dataset)\n",
        "out_profile= None\n",
        "transform = None\n",
        "band_files = glob(\"nz_imagery_sample/*.tif\")\n",
        "\n",
        "h = 0\n",
        "w = 0\n",
        "bands = {}\n",
        "\n",
        "with rasterio.open(band_files[0]) as data:\n",
        "    out_profile = data.profile.copy()\n",
        "    transform = data.transform\n",
        "    crs = data.crs\n",
        "    h = data.height\n",
        "    w = data.width\n",
        "\n",
        "out_profile.update({\"transform\": transform})\n",
        "out_profile.update({\"crs\": crs})\n",
        "\n",
        "for f in band_files:\n",
        "  data = rasterio.open(f)\n",
        "  ras_data = data.read(1)\n",
        "  ras_data = ras_data[0:h, 0:w]\n",
        "  bands[f.split(\"/\")[-1].split(\".\")[0]] = ras_data"
      ],
      "metadata": {
        "id": "5S0uKYkTMHII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Canculate Supportive Indices (NDVI, NDBI, NDWI)\n",
        "### **NDVI, NDBI, NDWI and Their Role in Image Classification**  \n",
        "\n",
        "In remote sensing, spectral indices like **NDVI (Normalized Difference Vegetation Index), NDBI (Normalized Difference Built-up Index), and NDWI (Normalized Difference Water Index)** help enhance specific land cover features for classification. These indices are derived from multispectral satellite imagery and play a crucial role in distinguishing vegetation, urban areas, and water bodies.  \n",
        "\n",
        "#### **1. NDVI (Normalized Difference Vegetation Index)**  \n",
        "NDVI is used to assess vegetation health and distribution. It is calculated using the Near-Infrared (NIR) and Red bands:  \n",
        "- Higher NDVI values indicate dense vegetation.  \n",
        "- Lower NDVI values suggest barren land, urban areas, or water.  \n",
        "\n",
        "#### **2. NDBI (Normalized Difference Built-up Index)**  \n",
        "NDBI helps in identifying built-up and urbanized areas. It is derived from the Shortwave Infrared (SWIR) and Near-Infrared (NIR) bands:  \n",
        "- High NDBI values indicate built-up regions.  \n",
        "- Low values represent vegetation, water, or bare land.  \n",
        "\n",
        "#### **3. NDWI (Normalized Difference Water Index)**  \n",
        "NDWI is used for water body detection and is calculated using the Green and Near-Infrared (NIR) bands:  \n",
        "- Higher NDWI values highlight water bodies.  \n",
        "- Lower values indicate land features like vegetation or urban areas.  \n",
        "\n",
        "#### **Role in Image Classification**  \n",
        "These indices serve as additional input bands in classification models such as **PCA + K-Means, Random Forest, or SVM** by:  \n",
        "- Enhancing spectral differences between land cover types.  \n",
        "- Improving accuracy in distinguishing vegetation, water, and urban areas.  \n",
        "- Reducing misclassification by incorporating meaningful spectral features.  \n",
        "\n",
        "By integrating NDVI, NDBI, and NDWI with multispectral bands, classification results become more precise, aiding in better Land Use/Land Cover (LULC) mapping."
      ],
      "metadata": {
        "id": "Q-j1kBmy3gmY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Add Derived Bands\n",
        "epsilon = 1e-6\n",
        "\n",
        "# Compute NDVI, NDWI, and NDBI\n",
        "ndvi = (bands[\"B08_10m\"] - bands[\"B04_10m\"]) / (bands[\"B08_10m\"] + bands[\"B04_10m\"] + epsilon)\n",
        "ndwi = (bands[\"B03_10m\"] - bands[\"B08_10m\"]) / (bands[\"B03_10m\"] + bands[\"B08_10m\"] + epsilon)\n",
        "ndbi = (bands[\"resampled_B11_20m\"] - bands[\"B08_10m\"]) / (bands[\"resampled_B11_20m\"] + bands[\"B08_10m\"] + epsilon)\n",
        "\n",
        "\n",
        "# Read bands and stack them\n",
        "stacked_image = np.stack([bands[\"B02_10m\"], bands[\"B03_10m\"], bands[\"B04_10m\"], bands[\"B08_10m\"], bands[\"resampled_B11_20m\"], bands[\"resampled_B12_20m\"], ndvi, ndwi, ndbi], axis=-1)"
      ],
      "metadata": {
        "id": "SDuYym053fVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K-Means clustring\n",
        "\n",
        "#### Setting Up K-Means for 5 Primary classes and Saving the output"
      ],
      "metadata": {
        "id": "SvcKo-Zl65oH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape for Clustering\n",
        "height, width, bands = stacked_image.shape\n",
        "pixels = stacked_image.reshape(-1, bands)  # Flatten to (n_samples, n_features)\n",
        "\n",
        "# Normalize Pixel Values\n",
        "scaler = StandardScaler()\n",
        "pixels_norm = scaler.fit_transform(pixels)\n",
        "\n",
        "# Define number of clusters (LULC classes)\n",
        "n_clusters = 5  # Example: Water, Vegetation, Urban, Bare Land, Agriculture\n",
        "\n",
        "# Train K-Means\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=20)\n",
        "clusters = kmeans.fit_predict(pixels_norm)\n",
        "\n",
        "# Reshape to Image Dimensions\n",
        "lulc_map = clusters.reshape(h, w)\n",
        "\n",
        "# Reshape back to image dimensions\n",
        "clustered_map = clusters.reshape(height, width)\n",
        "\n",
        "# Save K-Means Clustering Output\n",
        "out_profile.update({\"count\": 1})\n",
        "\n",
        "with rasterio.open(\"kmeans_indices.tif\",\"w\",**out_profile) as dst:\n",
        "    dst.write(clustered_map.astype(rasterio.uint8), 1)\n",
        "\n",
        "print(\"Clustered image saved as 'kmeans_indices.tif'\")"
      ],
      "metadata": {
        "id": "fYKIJ5DpZcwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preview The Classified Data"
      ],
      "metadata": {
        "id": "czZ1lCVr7R04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with rasterio.open(\"kmeans_indices.tif\") as src:\n",
        "    pca_data = src.read()\n",
        "    show(pca_data, cmap='viridis') # You can change the colormap\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "V0wyNrtWb1i4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOqkLpOWoSTae2gle+vVEpl",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}