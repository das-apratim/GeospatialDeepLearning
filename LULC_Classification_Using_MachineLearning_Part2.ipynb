{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/das-apratim/GeospatialDeepLearning/blob/main/LULC_Classification_Using_MachineLearning_Part2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Image Classification Using PCA & K-Means**  \n",
        "\n",
        "Image classification using **Principal Component Analysis (PCA) and K-Means clustering** is an **unsupervised learning approach** for segmenting satellite imagery into distinct land cover classes.  \n",
        "\n",
        "#### **Step 1: Principal Component Analysis (PCA)**\n",
        "PCA reduces the **dimensionality** of multispectral satellite images while preserving the most significant spectral information. By transforming correlated bands into a new set of **principal components**, it helps:  \n",
        "- Remove redundant information  \n",
        "- Highlight variance in spectral data  \n",
        "- Improve clustering performance  \n",
        "\n",
        "Typically, the **top 2-3 principal components** are used for further classification.  \n",
        "\n",
        "#### **Step 2: K-Means Clustering**  \n",
        "After PCA transformation, **K-Means clustering** is applied to group pixels into different land cover categories. K-Means:  \n",
        "- Assigns each pixel to the nearest cluster based on spectral similarity  \n",
        "- Segments the image into distinct land cover classes (e.g., vegetation, water, urban areas)  \n",
        "- Works without labeled training data (unsupervised classification)  \n",
        "\n",
        "This method is widely used in remote sensing for **Land Use/Land Cover (LULC) classification**, especially when ground truth labels are unavailable.  \n",
        "\n",
        "#### **Applications in Remote Sensing**  \n",
        "- Urban expansion monitoring  \n",
        "- Vegetation mapping (NDVI-based classification)  \n",
        "- Water body identification  \n",
        "- Disaster damage assessment  \n",
        "\n",
        "This approach is useful for rapid land cover classification without requiring supervised training data.\n",
        "\n",
        "\n",
        "\n",
        "## Download Sample Data"
      ],
      "metadata": {
        "id": "sEPQK878F4xb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GknWHzQhlBS"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/das-apratim/GeospatialDeepLearning/blob/main/data/sampled_data.zip?raw=true -O sampled_data.zip\n",
        "!unzip -q sampled_data.zip -d nz_imagery_sample"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Required Libraries"
      ],
      "metadata": {
        "id": "NDTVbs_CHrS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q rasterio"
      ],
      "metadata": {
        "id": "Uw1tZmMuHu3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "mnNZDCtYHBkR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import rasterio\n",
        "from rasterio.plot import show\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from scipy.ndimage import generic_filter\n",
        "from glob import glob\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA"
      ],
      "metadata": {
        "id": "MrPTvqERHEQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read Sentinal Bands"
      ],
      "metadata": {
        "id": "psutNbvB3Tq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentinel-2 band files (Modify this for your dataset)\n",
        "out_profile= None\n",
        "transform = None\n",
        "band_files = glob(\"nz_imagery_sample/*.tif\")\n",
        "\n",
        "h = 0\n",
        "w = 0\n",
        "bands = {}\n",
        "\n",
        "with rasterio.open(band_files[0]) as data:\n",
        "    out_profile = data.profile.copy()\n",
        "    transform = data.transform\n",
        "    crs = data.crs\n",
        "    h = data.height\n",
        "    w = data.width\n",
        "\n",
        "out_profile.update({\"transform\": transform})\n",
        "out_profile.update({\"crs\": crs})\n",
        "\n",
        "for f in band_files:\n",
        "  data = rasterio.open(f)\n",
        "  ras_data = data.read(1)\n",
        "  ras_data = ras_data[0:h, 0:w]\n",
        "  bands[f.split(\"/\")[-1].split(\".\")[0]] = ras_data"
      ],
      "metadata": {
        "id": "5S0uKYkTMHII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Canculate Supportive Indices (NDVI, NDBI, NDWI)\n",
        "### **NDVI, NDBI, NDWI and Their Role in Image Classification**  \n",
        "\n",
        "In remote sensing, spectral indices like **NDVI (Normalized Difference Vegetation Index), NDBI (Normalized Difference Built-up Index), and NDWI (Normalized Difference Water Index)** help enhance specific land cover features for classification. These indices are derived from multispectral satellite imagery and play a crucial role in distinguishing vegetation, urban areas, and water bodies.  \n",
        "\n",
        "#### **1. NDVI (Normalized Difference Vegetation Index)**  \n",
        "NDVI is used to assess vegetation health and distribution. It is calculated using the Near-Infrared (NIR) and Red bands:  \n",
        "- Higher NDVI values indicate dense vegetation.  \n",
        "- Lower NDVI values suggest barren land, urban areas, or water.  \n",
        "\n",
        "#### **2. NDBI (Normalized Difference Built-up Index)**  \n",
        "NDBI helps in identifying built-up and urbanized areas. It is derived from the Shortwave Infrared (SWIR) and Near-Infrared (NIR) bands:  \n",
        "- High NDBI values indicate built-up regions.  \n",
        "- Low values represent vegetation, water, or bare land.  \n",
        "\n",
        "#### **3. NDWI (Normalized Difference Water Index)**  \n",
        "NDWI is used for water body detection and is calculated using the Green and Near-Infrared (NIR) bands:  \n",
        "- Higher NDWI values highlight water bodies.  \n",
        "- Lower values indicate land features like vegetation or urban areas.  \n",
        "\n",
        "#### **Role in Image Classification**  \n",
        "These indices serve as additional input bands in classification models such as **PCA + K-Means, Random Forest, or SVM** by:  \n",
        "- Enhancing spectral differences between land cover types.  \n",
        "- Improving accuracy in distinguishing vegetation, water, and urban areas.  \n",
        "- Reducing misclassification by incorporating meaningful spectral features.  \n",
        "\n",
        "By integrating NDVI, NDBI, and NDWI with multispectral bands, classification results become more precise, aiding in better Land Use/Land Cover (LULC) mapping."
      ],
      "metadata": {
        "id": "Q-j1kBmy3gmY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Add Derived Bands\n",
        "epsilon = 1e-6\n",
        "\n",
        "# Compute NDVI, NDWI, and NDBI\n",
        "ndvi = (bands[\"B08_10m\"] - bands[\"B04_10m\"]) / (bands[\"B08_10m\"] + bands[\"B04_10m\"] + epsilon)\n",
        "ndwi = (bands[\"B03_10m\"] - bands[\"B08_10m\"]) / (bands[\"B03_10m\"] + bands[\"B08_10m\"] + epsilon)\n",
        "ndbi = (bands[\"resampled_B11_20m\"] - bands[\"B08_10m\"]) / (bands[\"resampled_B11_20m\"] + bands[\"B08_10m\"] + epsilon)\n",
        "\n",
        "\n",
        "# Read bands and stack them\n",
        "stacked_image = np.stack([bands[\"B02_10m\"], bands[\"B03_10m\"], bands[\"B04_10m\"], bands[\"B08_10m\"], bands[\"resampled_B11_20m\"], bands[\"resampled_B12_20m\"], ndvi, ndwi, ndbi], axis=-1)"
      ],
      "metadata": {
        "id": "SDuYym053fVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compute PCA for The whole image with 3 Principal components"
      ],
      "metadata": {
        "id": "nceXzNSd4JIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get Image Shape\n",
        "height, width, n_bands = stacked_image.shape\n",
        "print(f\"Original Image Shape: {stacked_image.shape}\")\n",
        "\n",
        "# Reshape to (n_samples, n_features) for PCA\n",
        "pixels = stacked_image.reshape(-1, n_bands)  # Flatten to (H*W, Bands)\n",
        "\n",
        "# Normalize Pixel Values\n",
        "scaler = StandardScaler()\n",
        "pixels_norm = scaler.fit_transform(pixels)\n",
        "\n",
        "# Apply PCA - Keep only 3 principal components\n",
        "n_components = 3\n",
        "pca = PCA(n_components=n_components)\n",
        "pca_result = pca.fit_transform(pixels_norm)\n",
        "\n",
        "# Reshape back to Image Shape (Height, Width, Components)\n",
        "pca_image = pca_result.reshape(height, width, n_components)\n",
        "\n",
        "print(f\"PCA Image Shape: {pca_image.shape}\")\n",
        "\n",
        "# Explained Variance\n",
        "print(\"Explained Variance per Component:\", pca.explained_variance_ratio_)\n",
        "print(\"Total Variance Captured:\", sum(pca.explained_variance_ratio_))"
      ],
      "metadata": {
        "id": "k5W67JGo4Xat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save PCA Components as MultiBand Raster and Preview Image"
      ],
      "metadata": {
        "id": "0JGYHwXW6GN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Set Raster Profile\n",
        "out_profile.update({\"count\": n_components})\n",
        "out_profile.update({\"transform\": transform})\n",
        "\n",
        "# Save PCA Components as a Multi-band GeoTIFF\n",
        "with rasterio.open(\"pca_with_indices.tif\",\"w\",**out_profile) as dst:\n",
        "    for i in range(n_components):\n",
        "        dst.write(pca_image[:, :, i], i+1)\n",
        "\n",
        "print(\"PCA-transformed image saved as 'pca_with_indices.tif'\")\n",
        "\n",
        "with rasterio.open(\"pca_with_indices.tif\") as src:\n",
        "    pca_data = src.read()\n",
        "    show(pca_data, cmap='jet') # You can change the colormap\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "AFXvsSZj6GlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K-Means clustring\n",
        "\n",
        "#### Setting Up K-Means for 5 Primary classes and Saving the output"
      ],
      "metadata": {
        "id": "SvcKo-Zl65oH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten PCA image for clustering\n",
        "pca_pixels = pca_image.reshape(-1, n_components)  # Shape: (n_samples, 3)\n",
        "\n",
        "# Apply K-Means\n",
        "n_clusters = 5  # Modify as needed\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
        "clusters = kmeans.fit_predict(pca_pixels)\n",
        "\n",
        "# Reshape back to image dimensions\n",
        "clustered_map = clusters.reshape(height, width)\n",
        "\n",
        "# Save K-Means Clustering Output\n",
        "out_profile.update({\"count\": 1})\n",
        "\n",
        "with rasterio.open(\"pca_kmeans_indices.tif\",\"w\",**out_profile) as dst:\n",
        "    dst.write(clustered_map.astype(rasterio.uint8), 1)\n",
        "\n",
        "print(\"Clustered image saved as 'pca_kmeans_indices.tif'\")"
      ],
      "metadata": {
        "id": "fYKIJ5DpZcwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preview The Classified Data"
      ],
      "metadata": {
        "id": "czZ1lCVr7R04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with rasterio.open(\"pca_kmeans_indices.tif\") as src:\n",
        "    pca_data = src.read()\n",
        "    show(pca_data) # You can change the colormap\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "V0wyNrtWb1i4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNKk1FcxWO2Dsn9MqaZKM91",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}